{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "#include_top=False removes the output layer of the model\n",
    "base_model = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get only the name\n",
    "base_model.layers[0].__class__.__name__\n",
    "#To see the input/output of a particular layer\n",
    "base_model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing all the layers by making their trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "#Checking this\n",
    "base_model.layers[12].trainable\n",
    "\n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(base_model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block5_pool/MaxPool:0' shape=(None, 7, 7, 512) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the ouput of the current model\n",
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we add our dense layers for a new prediction on top of the base model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(512, activation='relu')(top_model)   #First added FCL dense layer\n",
    "top_model = Dense(512, activation='relu')(top_model)    #Second added FCL dense layer\n",
    "top_model = Dense(256, activation='relu')(top_model)    #Third added FCL dense layer\n",
    "top_model = Dense(5, activation='softmax')(top_model)    #Output layer with 5 class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(None, 5) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see the top_model output\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMP: Mounting the base_model with the top_model\n",
    "from keras.models import Model\n",
    "newmodel = Model(inputs=base_model.input, outputs=top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(None, 5) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1b57d8ae648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b575021d88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b575035f08>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1b57d913e08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d91af08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d923e48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1b57d926308>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d923f48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d931e08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d92c448>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1b57d943f08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d943ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d94b508>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d94f408>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1b57d9567c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d95d908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d965d08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1b57d96dac8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1b57d971e08>,\n",
       " <keras.layers.core.Flatten at 0x1b501382b08>,\n",
       " <keras.layers.core.Dense at 0x1b501382b48>,\n",
       " <keras.layers.core.Dense at 0x1b501386148>,\n",
       " <keras.layers.core.Dense at 0x1b501393e48>,\n",
       " <keras.layers.core.Dense at 0x1b5013a4f48>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 27,955,525\n",
      "Trainable params: 13,240,837\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n",
      "Found 25 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#Converting to 4D\\nfor img_test in test_generator:\\n    img_test=np.expand_dims(img_test, axis=0)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing our images for recognition\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data=\"D:/Users/OWNER/MLOps-ws/ImageRecogniser_TransferLearning/5 Celeb Dataset/data/train/\"\n",
    "test_data=\"D:/Users/OWNER/MLOps-ws/ImageRecogniser_TransferLearning/5 Celeb Dataset/data/val/\"\n",
    "\n",
    "#Data image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical')\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_train in train_generator:\n",
    "    img_train=np.expand_dims(img_train, axis=0)'''\n",
    " \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_test in test_generator:\n",
    "    img_test=np.expand_dims(img_test, axis=0)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's compile our model\n",
    "from keras.optimizers import RMSprop\n",
    "newmodel.compile(optimizer = RMSprop(lr=0.0001),\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics =['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "93/93 [==============================] - 1366s 15s/step - loss: 0.8074 - accuracy: 0.7055 - val_loss: 0.6634 - val_accuracy: 0.6800\n",
      "Epoch 2/3\n",
      "93/93 [==============================] - 5467s 59s/step - loss: 0.1585 - accuracy: 0.9601 - val_loss: 0.4293 - val_accuracy: 0.8800\n",
      "Epoch 3/3\n",
      "93/93 [==============================] - 825s 9s/step - loss: 0.0710 - accuracy: 0.9778 - val_loss: 0.3226 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "history = newmodel.fit_generator(train_generator, epochs=3,steps_per_epoch=93, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.save('5CelebRecognizer_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('5CelebRecognizer_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - ben_afflek\n",
      "Class - madonna\n",
      "Class - mindy_kaling\n",
      "Class - madonna\n",
      "Class - mindy_kaling\n",
      "Class - mindy_kaling\n",
      "Class - mindy_kaling\n",
      "Class - ben_afflek\n",
      "Class - madonna\n",
      "Class - ben_afflek\n"
     ]
    }
   ],
   "source": [
    "#Testing the model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "five_celeb_dict = {\"[0]\": \"ben_afflek\", \n",
    "                      \"[1]\": \"elton_john\",\n",
    "                      \"[2]\": \"jerry_seinfeld\",\n",
    "                      \"[3]\": \"madonna\",\n",
    "                      \"[4]\": \"mindy_kaling\",\n",
    "                     }\n",
    "\n",
    "five_celeb_dict_n = {\"ben_afflek\": \"ben_afflek\", \n",
    "                      \"elton_john\": \"elton_john\",\n",
    "                      \"jerry_seinfeld\": \"jerry_seinfeld\",\n",
    "                      \"madonna\": \"madonna\",\n",
    "                      \"mindy_kaling\": \"mindy_kaling\",\n",
    "                      }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celeb =five_celeb_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celeb, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + five_celeb_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"D:/Users/OWNER/MLOps-ws/ImageRecogniser_TransferLearning/5 Celeb Dataset/val/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
